{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기부터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가. 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 만약에 Train/Evaluation 데이터를 따로 전처리 한다면?\n",
    "* 전처리 기준(특히 정규화 작업 시)이 달라져서 모델의 성능에 악영향을 줄 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 데이터 셋 로딩\n",
    "df = pd.read_csv(\"onenavi_train.csv\", sep = \"|\")\n",
    "df_eval = pd.read_csv(\"onenavi_evaluation.csv\", sep = \"|\")\n",
    "# 학습/평가 데이터의 전처리 기준을 통일하기위해 데이터 합본\n",
    "df_total=pd.concat([df,df_eval],ignore_index=True)\n",
    "# 추가 데이터 셋 로딩\n",
    "df_pnu = pd.read_csv(\"onenavi_pnu.csv\",sep=\"|\") # 주소(시도/시군구 정보)\n",
    "df_signal = pd.read_csv(\"onenavi_signal.csv\",sep=\"|\") # 경로의 신호등 갯수\n",
    "# 데이터 합치기\n",
    "df_total=pd.merge(df_total,df_pnu , on=\"RID\")\n",
    "df_total=pd.merge(df_total,df_signal , on=\"RID\")\n",
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이상치/결측치 처리\n",
    "## Trash를 판별하는 능력은 좋은 AI모델을 만드는 데 있어 핵심입니다.\n",
    "+ KeyPoint : 데이터의 형태를 살펴보고 불필요한 데이터를 정제할 수 있다.\n",
    "\n",
    "[참고] 공식 Document\n",
    "+ fillna(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)\n",
    "+ dropna(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가. 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습1. <u>df_total의 결측치를 확인하고 결측치가 존재한다면 제거해주세요.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.(Hint : dataframedf_total.isnull().sum() // dropna(), fillna())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나. 이상치 처리\n",
    "#### 이상치(Outlier)는 전적으로 연구자 혹은 개발자가 판단을 해야한다. 자세히 살펴보지않으면 놓치기 쉽상이다.\n",
    "#### \"자세히 보아야 드러난다. 오래 보아야 도움이 된다. Outlier가 그렇다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습2. <u>시각화 기법 및 데이터 분포를 확인하고 df_total의 이상치를 전처리해주세요.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습3. <u>이상치를 판단한 기준(아이디어)과 처리한 내용을 적어주세요.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 자유롭게 아이디어를 적어주세요. 그리고 실제로 이상치를 처리했다면 처리한 내용을 적어주세요.\n",
    "# 아이디어 :\n",
    "# 이상치 처리 :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 더미변수 생성\n",
    "## 범주형 데이터도 모델링에 활용할 수 있어야 합니다. 이를 위해 더미변수로 변환해주어야 합니다.\n",
    "+ KeyPoint : 범주형 변수를 더미변수로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 범주형 변수 중에 어떤 변수를 더미로 변환해볼까요?\n",
    "#### 요일, 시간, 시도 변수를 더미화 하면 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습4. <u>요일, 시간, 날짜 변수를 추가하고 요일, 시간, 날짜, level1_pnu를 더미변수로 만들어봅시다.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "# Hint1\n",
    "## for w in df_total['TIME_DEPARTUREDATE']:\n",
    "##     parse_data_w = parse(w)\n",
    "##     weekday_list.append(parse_data_w.weekday())\n",
    "##     hour_list.append(parse_data_w.hour)\n",
    "##     day_list.append(parse_data_w.day)\n",
    "# Hint2 : pandas.get_dummies\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가데이터 별도 저장 : 원본 기준(나중에 활용)\n",
    "new_df_eval=df_total[df_total['DAY']>=27]\n",
    "new_df_eval.to_csv(\"onenavi_evaluation_new.csv\",sep=\"|\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 데이터 스케일링\n",
    "##  Feature들의 크기, 범주를 정규화하는 과정을 통해 특정변수의 영향도를 조정해줄 수 있습니다.\n",
    "+ KeyPoint : 데이터 스케일링을 통해 AI모델 학습에 도움을 줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습5. <u>df_total을 MinMaxScaler로 데이터 스케일링을 진행하고 feature 변수로 저장해주세요.</u>\n",
    "* 단, 날짜가 스케일링이 되면 안됩니다. 별도로 저장해주었다가 나중에 합쳐주세요.\n",
    "* data_day = df_total['DAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.(Hint : from sklearn.preprocessing import MinMaxScaler)\n",
    "# 스케일링이 불가능한 데이터(문자형, 날짜형 등)와 우리의 목적인 Target(ET)은 스케일링을 하시면 안됩니다.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음 단계를 위해서 데이터를 저장하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 날짜를 합칠께요 : Train/Evaluation 분리를 위해 \n",
    "feature['DAY']=data_day\n",
    "# traindata 지정\n",
    "train_feature=feature[feature['DAY']<=24]\n",
    "train_feature=train_feature.drop(['DAY'],axis=1)\n",
    "eval_feature=feature[feature['DAY']>=27]\n",
    "eval_feature=eval_feature.drop(['DAY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(feature),len(train_feature),len(eval_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# target 저장\n",
    "train_target = df_total[df_total['DAY']<=24]['ET']\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV로 저장\n",
    "train_feature.to_csv('onenavi_train_feature.csv',index = False,sep='|')\n",
    "train_target.to_csv('onenavi_train_target.csv',index = False,sep='|')\n",
    "eval_feature.to_csv('onenavi_eval_feature.csv',index = False,sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
